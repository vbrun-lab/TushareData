#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡é‡åŒ–æ•°æ®ä¸‹è½½ç¨‹åºä¸»å…¥å£
æ•´åˆè‚¡ç¥¨ã€åŸºé‡‘ã€æŒ‡æ•°æ•°æ®ä¸‹è½½åŠŸèƒ½
æ”¯æŒå‘½ä»¤è¡Œå‚æ•°å’Œé…ç½®æ–‡ä»¶
"""

import argparse
import sys
import json
import pandas as pd
import logging
from pathlib import Path
from typing import List
from tqdm import tqdm

from data_downloader import DataDownloader
from stock_downloader import StockDownloader
from fund_downloader import FundDownloader
from index_downloader import IndexDownloader


class MainDownloader:
    """ä¸»ä¸‹è½½å™¨ï¼Œæ•´åˆæ‰€æœ‰åŠŸèƒ½"""
    
    def __init__(self, config_file: str = 'config.json'):
        self.config_file = config_file
        self.stock_downloader = StockDownloader(config_file)
        self.fund_downloader = FundDownloader(config_file)
        self.index_downloader = IndexDownloader(config_file)
        self.logger = self.stock_downloader.logger
    
    def update_all_reference_data(self):
        """æ›´æ–°æ‰€æœ‰åŸºç¡€æ•°æ®"""
        self.logger.info("å¼€å§‹æ›´æ–°æ‰€æœ‰åŸºç¡€æ•°æ®...")
        self.stock_downloader.update_reference_data()
        self.logger.info("æ‰€æœ‰åŸºç¡€æ•°æ®æ›´æ–°å®Œæˆ")
    
    def download_stocks(self, ts_codes: List[str] = None, frequencies: List[str] = None, 
                       limit: int = None, all_stocks: bool = False, use_config: bool = True, save_to_temp: bool = False):
        """ä¸‹è½½è‚¡ç¥¨æ•°æ®"""
        if all_stocks:
            self.stock_downloader.download_all_stocks(frequencies, limit, use_config, save_to_temp)
        elif ts_codes:
            self.stock_downloader.download_stock_list(ts_codes, frequencies)
        else:
            self.logger.warning("æœªæŒ‡å®šè¦ä¸‹è½½çš„è‚¡ç¥¨")
    
    def download_funds(self, ts_codes: List[str] = None, frequencies: List[str] = None,
                      limit: int = None, all_etfs: bool = False, all_lofs: bool = False, all_funds: bool = False, use_config: bool = True, save_to_temp: bool = False):
        """ä¸‹è½½åŸºé‡‘æ•°æ®"""
        if all_funds:
            # ä¸‹è½½æ‰€æœ‰åŸºé‡‘ï¼ˆETF + LOFï¼‰
            self.fund_downloader.download_all_etfs(frequencies, limit, use_config, save_to_temp)
            self.fund_downloader.download_all_lofs(frequencies, limit, use_config, save_to_temp)
        elif all_etfs:
            self.fund_downloader.download_all_etfs(frequencies, limit, use_config, save_to_temp)
        elif all_lofs:
            self.fund_downloader.download_all_lofs(frequencies, limit, use_config, save_to_temp)
        elif ts_codes:
            self.fund_downloader.download_fund_list(ts_codes, frequencies)
        else:
            self.logger.warning("æœªæŒ‡å®šè¦ä¸‹è½½çš„åŸºé‡‘")
    
    def download_indices(self, ts_codes: List[str] = None, major_only: bool = False,
                        market: str = 'ALL', limit: int = None, use_config: bool = True, save_to_temp: bool = False, frequencies: List[str] = None):
        """ä¸‹è½½æŒ‡æ•°æ•°æ®"""
        if major_only:
            self.index_downloader.download_major_indices(use_config=use_config, save_to_temp=save_to_temp, frequencies=frequencies)
        elif ts_codes:
            self.index_downloader.download_index_list(ts_codes, save_to_temp=save_to_temp, frequencies=frequencies)
        else:
            self.index_downloader.download_all_indices(market, limit, use_config=use_config, save_to_temp=save_to_temp, frequencies=frequencies)
    
    def download_by_config(self, save_to_temp: bool = False):
        """æ ¹æ®é…ç½®æ–‡ä»¶ä¸‹è½½æ•°æ®"""
        self.logger.info("å¼€å§‹æ ¹æ®é…ç½®æ–‡ä»¶ä¸‹è½½æ•°æ®...")
        
        # è¯»å–é…ç½®
        with open(self.config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        date_ranges = config.get('date_ranges', {})
        custom_ranges = date_ranges.get('custom_ranges', {})
        
        # æ›´æ–°åŸºç¡€æ•°æ®
        self.update_all_reference_data()
        
        # ä¸‹è½½è‚¡ç¥¨æ•°æ®
        if 'stocks' in custom_ranges and custom_ranges['stocks'].get('enabled', True):
            self.logger.info("ä¸‹è½½è‚¡ç¥¨æ•°æ®...")
            self.download_stocks(all_stocks=True, use_config=True, save_to_temp=save_to_temp)
        
        # ä¸‹è½½åŸºé‡‘æ•°æ®
        if 'funds' in custom_ranges and custom_ranges['funds'].get('enabled', True):
            fund_config = custom_ranges['funds']
            fund_types = fund_config.get('name', ['ETF', 'LOF'])
            
            if 'ETF' in fund_types:
                self.logger.info("ä¸‹è½½ETFæ•°æ®...")
                self.download_funds(all_etfs=True, use_config=True, save_to_temp=save_to_temp)
            
            if 'LOF' in fund_types:
                self.logger.info("ä¸‹è½½LOFæ•°æ®...")
                self.download_funds(all_lofs=True, use_config=True, save_to_temp=save_to_temp)
        
        # ä¸‹è½½æŒ‡æ•°æ•°æ®
        if 'indices' in custom_ranges and custom_ranges['indices'].get('enabled', True):
            self.logger.info("ä¸‹è½½æŒ‡æ•°æ•°æ®...")
            
            # æ ¹æ®update_modeå†³å®šæŒ‡æ•°ä¸‹è½½ç­–ç•¥
            update_mode = date_ranges.get('update_mode', 'incremental')
            if update_mode == 'custom':
                # customæ¨¡å¼ï¼šä½¿ç”¨custom_rangesä¸­çš„major_onlyè®¾ç½®
                indices_config = custom_ranges['indices']
                major_only = indices_config.get('major_only', True)
                limit = indices_config.get('limits')
            else:
                # full/incrementalæ¨¡å¼ï¼šä¸‹è½½å…¨éƒ¨æŒ‡æ•°ï¼Œä¸ä½¿ç”¨major_onlyé™åˆ¶
                major_only = False  # å¼ºåˆ¶ä¸‹è½½å…¨éƒ¨æŒ‡æ•°
                limit = date_ranges.get('limits')
            
            if major_only:
                self.download_indices(major_only=True, use_config=True, save_to_temp=save_to_temp)
            else:
                # ä¸‹è½½å…¨éƒ¨æŒ‡æ•°ï¼Œä½¿ç”¨é…ç½®ç­›é€‰
                self.download_indices(major_only=False, limit=limit, use_config=True, save_to_temp=save_to_temp)
        
        self.logger.info("é…ç½®é©±åŠ¨çš„æ•°æ®ä¸‹è½½å®Œæˆ")
    
    def download_all(self, frequencies: List[str] = None, limit: int = None):
        """ä¸‹è½½æ‰€æœ‰ç±»å‹çš„æ•°æ®"""
        self.logger.info("å¼€å§‹ä¸‹è½½æ‰€æœ‰ç±»å‹çš„æ•°æ®...")
        
        # æ›´æ–°åŸºç¡€æ•°æ®
        self.update_all_reference_data()
        
        # ä¸‹è½½å…¨éƒ¨æŒ‡æ•°
        self.logger.info("ä¸‹è½½å…¨éƒ¨æŒ‡æ•°æ•°æ®...")
        self.download_indices(major_only=False, use_config=False)
        
        # ä¸‹è½½ETFæ•°æ®
        self.logger.info("ä¸‹è½½ETFæ•°æ®...")
        self.download_funds(all_etfs=True, frequencies=frequencies, limit=limit, use_config=False)
        
        # ä¸‹è½½è‚¡ç¥¨æ•°æ®ï¼ˆå¯ä»¥è®¾ç½®é™åˆ¶æ•°é‡é¿å…ä¸‹è½½æ—¶é—´è¿‡é•¿ï¼‰
        stock_limit = limit or 100  # é»˜è®¤é™åˆ¶100åªè‚¡ç¥¨
        self.logger.info(f"ä¸‹è½½è‚¡ç¥¨æ•°æ®ï¼ˆé™åˆ¶{stock_limit}åªï¼‰...")
        self.download_stocks(all_stocks=True, frequencies=frequencies, limit=stock_limit, use_config=False)
        
        self.logger.info("æ‰€æœ‰æ•°æ®ä¸‹è½½å®Œæˆ")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Aè‚¡é‡åŒ–æ•°æ®ä¸‹è½½ç¨‹åº')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--config', '-c', default='config.json', 
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.json)')
    parser.add_argument('--interactive', '-i', action='store_true',
                       help='å¯åŠ¨äº¤äº’å¼èœå•ç•Œé¢')
    parser.add_argument('--update-ref', action='store_true',
                       help='æ›´æ–°åŸºç¡€æ•°æ®ï¼ˆè‚¡ç¥¨åˆ—è¡¨ã€åŸºé‡‘åˆ—è¡¨ã€äº¤æ˜“æ—¥å†ç­‰ï¼‰')
    
    # æ•°æ®ç±»å‹é€‰æ‹©
    parser.add_argument('--stocks', action='store_true', help='ä¸‹è½½è‚¡ç¥¨æ•°æ®')
    parser.add_argument('--funds', action='store_true', help='ä¸‹è½½åŸºé‡‘æ•°æ®')
    parser.add_argument('--indices', action='store_true', help='ä¸‹è½½æŒ‡æ•°æ•°æ®')
    parser.add_argument('--all', action='store_true', help='ä¸‹è½½æ‰€æœ‰ç±»å‹æ•°æ®')
    
    # è‚¡ç¥¨ç›¸å…³å‚æ•°
    parser.add_argument('--stock-codes', nargs='+', help='æŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—è¡¨')
    parser.add_argument('--all-stocks', action='store_true', help='ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨')
    
    # åŸºé‡‘ç›¸å…³å‚æ•°
    parser.add_argument('--fund-codes', nargs='+', help='æŒ‡å®šåŸºé‡‘ä»£ç åˆ—è¡¨')
    parser.add_argument('--all-etfs', action='store_true', help='ä¸‹è½½æ‰€æœ‰ETF')
    
    # æŒ‡æ•°ç›¸å…³å‚æ•°
    parser.add_argument('--index-codes', nargs='+', help='æŒ‡å®šæŒ‡æ•°ä»£ç åˆ—è¡¨')
    parser.add_argument('--major-indices', action='store_true', help='ä¸‹è½½ä¸»è¦æŒ‡æ•°')
    parser.add_argument('--index-market', choices=['SSE', 'SZSE', 'ALL'], 
                       default='ALL', help='æŒ‡æ•°å¸‚åœºç­›é€‰')
    
    # é€šç”¨å‚æ•°
    parser.add_argument('--frequencies', '-f', nargs='+', 
                       choices=['daily', 'minute_1', 'minute_5', 'minute_15', 'minute_30', 'minute_60'],
                       default=['daily'], help='æ•°æ®é¢‘ç‡')
    parser.add_argument('--limit', '-l', type=int, help='é™åˆ¶ä¸‹è½½æ•°é‡')
    parser.add_argument('--start-date', type=str, 
                       help='å¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYYMMDD, å¦‚: 20190101)')
    parser.add_argument('--end-date', type=str, 
                       help='ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYYMMDD, å¦‚: 20251231)')
    parser.add_argument('--fill-missing-minutes', action='store_true',
                       help='è¡¥é½ç¼ºå¤±çš„è‚¡ç¥¨1åˆ†é’Ÿæ•°æ®')
    
    return parser.parse_args()


def check_config_file(config_file: str):
    """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
    if not Path(config_file).exists():
        print(f"é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶...")
        
        default_config = {
            "tushare_token": "YOUR_TOKEN_HERE",
            "data_root": "./data",
            "sleep_secs": 0.12,
            "retry": 3,
            "threads": 4,
            "frequencies": ["daily", "minute_1"],
            "etf_filter": {
                "min_list_date": "20100101",
                "include_delisted": False
            },
            "download_settings": {
                "lookback_days": 1800,
                "batch_size": 100,
                "max_records_per_call": 8000
            },
            "logging": {
                "level": "INFO",
                "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            }
        }
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(default_config, f, ensure_ascii=False, indent=2)
        
        print(f"é»˜è®¤é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_file}")
        print("è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œè®¾ç½®æ‚¨çš„tushare_tokenï¼Œç„¶åé‡æ–°è¿è¡Œç¨‹åº")
        return False
    
    # æ£€æŸ¥tokené…ç½®
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        token = config.get('tushare_token', '')
        if not token or token == 'YOUR_TOKEN_HERE':
            print("è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„tushare_token")
            return False
            
    except Exception as e:
        print(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    return True


def apply_date_args_to_config(config_file: str, start_date: str = None, end_date: str = None) -> str:
    """åº”ç”¨å‘½ä»¤è¡Œæ—¥æœŸå‚æ•°åˆ°é…ç½®æ–‡ä»¶ï¼Œè¿”å›ä¿®æ”¹åçš„é…ç½®æ–‡ä»¶è·¯å¾„"""
    if not start_date and not end_date:
        return config_file  # æ²¡æœ‰æ—¥æœŸå‚æ•°ï¼Œç›´æ¥è¿”å›åŸé…ç½®
    
    try:
        # è¯»å–åŸé…ç½®
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # ä¿®æ”¹æ—¥æœŸèŒƒå›´
        if 'date_ranges' not in config:
            config['date_ranges'] = {}
        
        if start_date:
            config['date_ranges']['default_start_date'] = start_date
            print(f"ğŸ“… è®¾ç½®å¼€å§‹æ—¥æœŸ: {start_date}")
        
        if end_date:
            config['date_ranges']['default_end_date'] = end_date
            print(f"ğŸ“… è®¾ç½®ç»“æŸæ—¥æœŸ: {end_date}")
        
        # å¦‚æœæä¾›äº†æ—¥æœŸå‚æ•°ï¼Œå¼ºåˆ¶ä½¿ç”¨fullæ¨¡å¼
        if start_date or end_date:
            config['date_ranges']['update_mode'] = 'full'
            print(f"ğŸ”„ æ›´æ–°æ¨¡å¼: full (å…¨é‡ä¸‹è½½)")
        
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        import tempfile
        import os
        temp_fd, temp_config_file = tempfile.mkstemp(suffix='.json', prefix='config_temp_')
        try:
            with os.fdopen(temp_fd, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            return temp_config_file
        except Exception as e:
            os.close(temp_fd)
            if os.path.exists(temp_config_file):
                os.unlink(temp_config_file)
            raise e
            
    except Exception as e:
        print(f"âš ï¸ åº”ç”¨æ—¥æœŸå‚æ•°å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸé…ç½®æ–‡ä»¶")
        return config_file


def fill_missing_minutes(config_file: str = 'config.json'):
    """è¡¥é½ç¼ºå¤±çš„è‚¡ç¥¨1åˆ†é’Ÿæ•°æ®"""
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    
    try:
        # åˆ›å»ºä¸‹è½½å™¨
        downloader = StockDownloader(config_file)
        
        # è¯»å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        stock_basic_path = Path('data/reference/stock_basic.csv')
        if not stock_basic_path.exists():
            logger.error("æœªæ‰¾åˆ° data/reference/stock_basic.csvï¼Œè¯·å…ˆæ‰§è¡Œ [1] æ›´æ–°åŸºç¡€æ•°æ®")
            return
        
        stock_basic = pd.read_csv(stock_basic_path)
        total_stocks = len(stock_basic)
        logger.info(f'æ€»è‚¡ç¥¨æ•°é‡: {total_stocks:,}')
        
        # ç»Ÿè®¡å·²ä¸‹è½½çš„1åˆ†é’Ÿæ•°æ®æ–‡ä»¶
        minute_1_dir = Path('data/data/equities/minute_1')
        minute_1_dir.mkdir(parents=True, exist_ok=True)
        downloaded_files = list(minute_1_dir.glob('*.parquet'))
        downloaded_count = len(downloaded_files)
        logger.info(f'å·²ä¸‹è½½1åˆ†é’Ÿæ•°æ®çš„è‚¡ç¥¨æ•°é‡: {downloaded_count:,}')
        
        # è®¡ç®—æœªä¸‹è½½çš„è‚¡ç¥¨
        downloaded_codes = set()
        for file in downloaded_files:
            ts_code = file.stem
            downloaded_codes.add(ts_code)
        
        all_codes = set(stock_basic['ts_code'].tolist())
        missing_codes = all_codes - downloaded_codes
        missing_count = len(missing_codes)
        
        logger.info(f'æœªä¸‹è½½1åˆ†é’Ÿæ•°æ®çš„è‚¡ç¥¨æ•°é‡: {missing_count:,}')
        if total_stocks > 0:
            completion_rate = downloaded_count / total_stocks * 100
            logger.info(f'ä¸‹è½½å®Œæˆç‡: {completion_rate:.1f}%')
        
        if missing_count == 0:
            logger.info('âœ… æ‰€æœ‰è‚¡ç¥¨çš„1åˆ†é’Ÿæ•°æ®éƒ½å·²ä¸‹è½½å®Œæˆï¼')
            return
        
        # æ˜¾ç¤ºå‰20ä¸ªæœªä¸‹è½½çš„è‚¡ç¥¨
        missing_list = sorted(list(missing_codes))[:20]
        logger.info(f'å‰20ä¸ªæœªä¸‹è½½çš„è‚¡ç¥¨ä»£ç :')
        for code in missing_list:
            stock_info = stock_basic[stock_basic['ts_code'] == code]
            if not stock_info.empty:
                name = stock_info.iloc[0]['name']
                list_date = stock_info.iloc[0]['list_date']
                logger.info(f'  {code} - {name} (ä¸Šå¸‚æ—¥æœŸ: {list_date})')
        
        # å¼€å§‹è¡¥å……ä¸‹è½½
        logger.info(f'å¼€å§‹è¡¥å……ä¸‹è½½ {missing_count:,} åªè‚¡ç¥¨çš„1åˆ†é’Ÿæ•°æ®...')
        
        # å°†ç¼ºå¤±çš„è‚¡ç¥¨ä»£ç è½¬æ¢ä¸ºåˆ—è¡¨
        missing_list = sorted(list(missing_codes))
        
        # åˆ†æ‰¹ä¸‹è½½ï¼Œæ¯æ‰¹100åªè‚¡ç¥¨
        batch_size = 100
        total_batches = (len(missing_list) + batch_size - 1) // batch_size
        
        success_count = 0
        error_count = 0
        
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
        with tqdm(total=len(missing_list), desc="è¡¥é½åˆ†é’Ÿæ•°æ®", unit="åª", ncols=100) as pbar:
            for i in range(0, len(missing_list), batch_size):
                batch_codes = missing_list[i:i+batch_size]
                batch_num = i // batch_size + 1
                
                # æ›´æ–°è¿›åº¦æ¡æè¿°
                pbar.set_description(f"æ‰¹æ¬¡ {batch_num}/{total_batches}")
                
                try:
                    # ä¸‹è½½è¿™æ‰¹è‚¡ç¥¨çš„1åˆ†é’Ÿæ•°æ®
                    downloader.download_stock_list(batch_codes, ['minute_1'])
                    success_count += len(batch_codes)
                    pbar.update(len(batch_codes))
                except Exception as e:
                    logger.error(f'âŒ ç¬¬ {batch_num} æ‰¹ä¸‹è½½å¤±è´¥: {e}')
                    error_count += len(batch_codes)
                    pbar.update(len(batch_codes))  # å³ä½¿å¤±è´¥ä¹Ÿæ›´æ–°è¿›åº¦
                    continue
        
        logger.info(f'è¡¥å……ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {success_count:,}, å¤±è´¥: {error_count:,}')
        
    except Exception as e:
        logger.error(f'è¡¥é½åˆ†é’Ÿæ•°æ®å¤±è´¥: {e}')
        raise


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not check_config_file(args.config):
        sys.exit(1)
    
    # åº”ç”¨å‘½ä»¤è¡Œæ—¥æœŸå‚æ•°
    actual_config_file = apply_date_args_to_config(
        args.config, 
        args.start_date, 
        args.end_date
    )
    
    # å¯åŠ¨äº¤äº’å¼ç•Œé¢
    if args.interactive:
        from interactive_menu import InteractiveMenu
        menu = InteractiveMenu(actual_config_file)
        menu.run()
        # æ¸…ç†ä¸´æ—¶é…ç½®æ–‡ä»¶
        if actual_config_file != args.config:
            import os
            try:
                os.unlink(actual_config_file)
            except:
                pass
        return
    
    try:
        # åˆ›å»ºä¸»ä¸‹è½½å™¨
        downloader = MainDownloader(actual_config_file)
        
        # æ›´æ–°åŸºç¡€æ•°æ®
        if args.update_ref:
            downloader.update_all_reference_data()
            return
        
        # è¡¥é½ç¼ºå¤±çš„åˆ†é’Ÿæ•°æ®
        if args.fill_missing_minutes:
            fill_missing_minutes(actual_config_file)
            return
        
        # ä¸‹è½½æ‰€æœ‰æ•°æ®
        if args.all:
            downloader.download_all(args.frequencies, args.limit)
            return
        
        # ä¸‹è½½è‚¡ç¥¨æ•°æ®
        if args.stocks or args.stock_codes or args.all_stocks:
            downloader.download_stocks(
                ts_codes=args.stock_codes,
                frequencies=args.frequencies,
                limit=args.limit,
                all_stocks=args.all_stocks
            )
        
        # ä¸‹è½½åŸºé‡‘æ•°æ®
        if args.funds or args.fund_codes or args.all_etfs:
            downloader.download_funds(
                ts_codes=args.fund_codes,
                frequencies=args.frequencies,
                limit=args.limit,
                all_etfs=args.all_etfs
            )
        
        # ä¸‹è½½æŒ‡æ•°æ•°æ®
        if args.indices or args.index_codes or args.major_indices:
            downloader.download_indices(
                ts_codes=args.index_codes,
                major_only=args.major_indices,
                market=args.index_market,
                limit=args.limit
            )
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•ä¸‹è½½é€‰é¡¹ï¼Œæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        if not any([args.stocks, args.funds, args.indices, args.all,
                   args.stock_codes, args.fund_codes, args.index_codes,
                   args.all_stocks, args.all_etfs, args.major_indices]):
            print("è¯·æŒ‡å®šè¦ä¸‹è½½çš„æ•°æ®ç±»å‹ï¼Œä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯")
            print("\nå¸¸ç”¨å‘½ä»¤ç¤ºä¾‹:")
            print("  python main.py --interactive                   # å¯åŠ¨äº¤äº’å¼èœå•ï¼ˆæ¨èï¼‰")
            print("  python main.py --update-ref                    # æ›´æ–°åŸºç¡€æ•°æ®")
            print("  python main.py --major-indices                 # ä¸‹è½½ä¸»è¦æŒ‡æ•°")
            print("  python main.py --all-etfs --limit 50           # ä¸‹è½½50åªETF")
            print("  python main.py --stock-codes 000001.SZ 600000.SH  # ä¸‹è½½æŒ‡å®šè‚¡ç¥¨")
            print("  python main.py --all --limit 10                # ä¸‹è½½æ‰€æœ‰ç±»å‹æ•°æ®ï¼ˆé™åˆ¶æ•°é‡ï¼‰")
            print("  python main.py --all-stocks --start-date 20190101 --end-date 20251231  # æŒ‡å®šæ—¥æœŸèŒƒå›´ä¸‹è½½")
            print("  python main.py --fill-missing-minutes                    # è¡¥é½ç¼ºå¤±çš„åˆ†é’Ÿæ•°æ®")
            
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    finally:
        # æ¸…ç†ä¸´æ—¶é…ç½®æ–‡ä»¶
        if actual_config_file != args.config:
            import os
            try:
                os.unlink(actual_config_file)
            except:
                pass


if __name__ == "__main__":
    main() 