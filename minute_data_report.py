#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡1åˆ†é’Ÿæ•°æ®å¥åº·æ£€æŸ¥ä¸è¡¥é½å»ºè®®å·¥å…·
æ•´åˆäº† check_status.pyã€analyze_minute_data.pyã€final_analysis.py çš„åŠŸèƒ½
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
import sys

def format_date(date_str):
    """æ ¼å¼åŒ–æ—¥æœŸå­—ç¬¦ä¸²ä¸ºå¯è¯»æ ¼å¼"""
    date_str = str(date_str)
    if len(date_str) == 8:
        return f'{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}'
    return date_str

def check_basic_status():
    """åŸºç¡€çŠ¶æ€æ£€æŸ¥ï¼ˆæ¥è‡ª check_status.pyï¼‰"""
    print("=" * 60)
    print("ğŸ“Š Aè‚¡1åˆ†é’Ÿæ•°æ®åŸºç¡€çŠ¶æ€æ£€æŸ¥")
    print("=" * 60)
    
    try:
        # è¯»å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        stock_basic = pd.read_csv('data/reference/stock_basic.csv')
        total_stocks = len(stock_basic)
        print(f'æ€»è‚¡ç¥¨æ•°é‡: {total_stocks:,}')
    except FileNotFoundError:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° data/reference/stock_basic.csv")
        print("   è¯·å…ˆæ‰§è¡Œ [1] æ›´æ–°åŸºç¡€æ•°æ®")
        return None, None, None
    
    # ç»Ÿè®¡å·²ä¸‹è½½çš„1åˆ†é’Ÿæ•°æ®æ–‡ä»¶
    minute_1_dir = Path('data/data/equities/minute_1')
    minute_1_dir.mkdir(parents=True, exist_ok=True)
    downloaded_files = list(minute_1_dir.glob('*.parquet'))
    downloaded_count = len(downloaded_files)
    
    print(f'å·²ä¸‹è½½1åˆ†é’Ÿæ•°æ®çš„è‚¡ç¥¨æ•°é‡: {downloaded_count:,}')
    
    # è®¡ç®—æœªä¸‹è½½çš„è‚¡ç¥¨
    downloaded_codes = set()
    for file in downloaded_files:
        ts_code = file.stem
        downloaded_codes.add(ts_code)
    
    all_codes = set(stock_basic['ts_code'].tolist())
    missing_codes = all_codes - downloaded_codes
    missing_count = len(missing_codes)
    
    print(f'æœªä¸‹è½½1åˆ†é’Ÿæ•°æ®çš„è‚¡ç¥¨æ•°é‡: {missing_count:,}')
    if total_stocks > 0:
        completion_rate = downloaded_count / total_stocks * 100
        print(f'ä¸‹è½½å®Œæˆç‡: {completion_rate:.1f}%')
    
    # æ˜¾ç¤ºå‰20ä¸ªæœªä¸‹è½½çš„è‚¡ç¥¨
    if missing_codes:
        missing_list = sorted(list(missing_codes))[:20]
        print(f'\nå‰20ä¸ªæœªä¸‹è½½çš„è‚¡ç¥¨:')
        for code in missing_list:
            stock_info = stock_basic[stock_basic['ts_code'] == code]
            if not stock_info.empty:
                name = stock_info.iloc[0]['name']
                list_date = stock_info.iloc[0]['list_date']
                print(f'  {code} - {name} (ä¸Šå¸‚æ—¥æœŸ: {list_date})')
    
    return stock_basic, downloaded_files, missing_codes

def analyze_time_ranges(downloaded_files, stock_basic):
    """æ•°æ®æ—¶é—´èŒƒå›´åˆ†æï¼ˆæ¥è‡ª analyze_minute_data.pyï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´åˆ†æ")
    print("=" * 60)
    
    if not downloaded_files:
        print("âš ï¸  æ²¡æœ‰å·²ä¸‹è½½çš„æ•°æ®æ–‡ä»¶")
        return None
    
    time_ranges = []
    sample_size = min(100, len(downloaded_files))
    print(f'åˆ†ææ ·æœ¬: {sample_size} ä¸ªæ–‡ä»¶')
    
    print('\nå‰10ä¸ªæ–‡ä»¶çš„è¯¦ç»†æ—¶é—´èŒƒå›´:')
    for i, file in enumerate(downloaded_files[:sample_size]):
        try:
            df = pd.read_parquet(file)
            if not df.empty and 'trade_time' in df.columns:
                min_time = df['trade_time'].min()
                max_time = df['trade_time'].max()
                record_count = len(df)
                
                min_date = min_time[:10] if isinstance(min_time, str) else str(min_time)[:10]
                max_date = max_time[:10] if isinstance(max_time, str) else str(max_time)[:10]
                
                time_ranges.append({
                    'ts_code': file.stem,
                    'min_date': min_date,
                    'max_date': max_date,
                    'records': record_count
                })
                
                if i < 10:
                    print(f'  {file.stem}: {min_date} åˆ° {max_date} (å…±{record_count:,}æ¡è®°å½•)')
        except Exception as e:
            print(f'  {file.stem}: è¯»å–å¤±è´¥ - {e}')
    
    if not time_ranges:
        print("âš ï¸  æ— æ³•è¯»å–ä»»ä½•æ•°æ®æ–‡ä»¶")
        return None
    
    df_ranges = pd.DataFrame(time_ranges)
    
    print(f'\nèµ·å§‹æ—¥æœŸåˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰:')
    start_dates = df_ranges['min_date'].value_counts().head(10)
    for date, count in start_dates.items():
        print(f'  {date}: {count} åªè‚¡ç¥¨')
    
    print(f'\nç»“æŸæ—¥æœŸåˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰:')
    end_dates = df_ranges['max_date'].value_counts().head(10)
    for date, count in end_dates.items():
        print(f'  {date}: {count} åªè‚¡ç¥¨')
    
    print(f'\nè®°å½•æ•°ç»Ÿè®¡:')
    records_stats = df_ranges['records'].describe()
    print(f'  å¹³å‡è®°å½•æ•°: {records_stats["mean"]:,.0f}')
    print(f'  æœ€å°‘è®°å½•æ•°: {records_stats["min"]:,.0f}')
    print(f'  æœ€å¤šè®°å½•æ•°: {records_stats["max"]:,.0f}')
    print(f'  ä¸­ä½æ•°è®°å½•æ•°: {records_stats["50%"]:,.0f}')
    
    # å¼‚å¸¸æ£€æµ‹
    print(f'\nå¼‚å¸¸æ£€æµ‹:')
    
    # æ£€æŸ¥èµ·å§‹æ—¥æœŸå¼‚å¸¸
    normal_start = '2019-01-02'
    abnormal_start = df_ranges[df_ranges['min_date'] != normal_start]
    if not abnormal_start.empty:
        print(f'  âš ï¸  èµ·å§‹æ—¥æœŸå¼‚å¸¸çš„è‚¡ç¥¨ ({len(abnormal_start)} åª):')
        for _, row in abnormal_start.head(5).iterrows():
            print(f'    {row["ts_code"]}: {row["min_date"]} åˆ° {row["max_date"]} ({row["records"]:,}æ¡)')
    else:
        print(f'  âœ… èµ·å§‹æ—¥æœŸæ­£å¸¸ï¼ˆå‡ä¸º {normal_start}ï¼‰')
    
    # æ£€æŸ¥è®°å½•æ•°å¼‚å¸¸
    median_records = records_stats['50%']
    threshold = median_records * 0.5
    abnormal_records = df_ranges[df_ranges['records'] < threshold]
    if not abnormal_records.empty:
        print(f'  âš ï¸  è®°å½•æ•°å¼‚å¸¸çš„è‚¡ç¥¨ ({len(abnormal_records)} åªï¼Œå°‘äºä¸­ä½æ•°çš„50%):')
        for _, row in abnormal_records.head(5).iterrows():
            print(f'    {row["ts_code"]}: {row["records"]:,}æ¡è®°å½•')
    else:
        print(f'  âœ… è®°å½•æ•°æ­£å¸¸')
    
    return df_ranges

def check_metadata():
    """å…ƒæ•°æ®æ–‡ä»¶æ£€æŸ¥"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ å…ƒæ•°æ®æ–‡ä»¶æ£€æŸ¥")
    print("=" * 60)
    
    meta_file = Path('data/meta/last_sync_equities_minute_1.csv')
    
    if not meta_file.exists():
        print("âš ï¸  å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: data/meta/last_sync_equities_minute_1.csv")
        return None
    
    try:
        meta_df = pd.read_csv(meta_file)
        print(f'å…ƒæ•°æ®è®°å½•æ•°: {len(meta_df):,}')
        
        # æ£€æŸ¥æ—¥æœŸæ ¼å¼å¼‚å¸¸
        if 'last_date' in meta_df.columns:
            abnormal_dates = meta_df[meta_df['last_date'].astype(str).str.len() != 8]
            if not abnormal_dates.empty:
                print(f'âš ï¸  æ—¥æœŸæ ¼å¼å¼‚å¸¸çš„è®°å½•: {len(abnormal_dates)} æ¡')
                print('å¼‚å¸¸æ—¥æœŸæ ·æœ¬:')
                for _, row in abnormal_dates.head(5).iterrows():
                    print(f'  {row["ts_code"]}: {row["last_date"]}')
            else:
                print('âœ… æ—¥æœŸæ ¼å¼æ­£å¸¸')
            
            print('\næœ€æ–°æ—¥æœŸåˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰:')
            date_counts = meta_df['last_date'].value_counts().head(10)
            for date, count in date_counts.items():
                readable_date = format_date(date)
                print(f'  {readable_date}: {count:,} åªè‚¡ç¥¨')
        
        return meta_df
    except Exception as e:
        print(f'âŒ è¯»å–å…ƒæ•°æ®å¤±è´¥: {e}')
        return None

def analyze_completeness(stock_basic, meta_df):
    """æ•°æ®å®Œæ•´æ€§åˆ†æï¼ˆæ¥è‡ª final_analysis.pyï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ” æ•°æ®å®Œæ•´æ€§åˆ†æ")
    print("=" * 60)
    
    if meta_df is None:
        print("âš ï¸  æ— æ³•è¿›è¡Œå®Œæ•´æ€§åˆ†æï¼ˆå…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼‰")
        return
    
    total_stocks = len(stock_basic)
    downloaded_count = len(meta_df)
    
    print(f'æ€»è‚¡ç¥¨æ•°é‡: {total_stocks:,}')
    print(f'å·²ä¸‹è½½è‚¡ç¥¨æ•°é‡: {downloaded_count:,}')
    if total_stocks > 0:
        print(f'ä¸‹è½½å®Œæˆç‡: {downloaded_count/total_stocks*100:.1f}%')
    
    if 'last_date' not in meta_df.columns:
        print("âš ï¸  å…ƒæ•°æ®ç¼ºå°‘ last_date å­—æ®µ")
        return
    
    # åˆ†ææœ€æ–°æ—¥æœŸåˆ†å¸ƒ
    print(f'\næœ€æ–°æ•°æ®æ—¥æœŸåˆ†å¸ƒ:')
    date_counts = meta_df['last_date'].value_counts()
    
    if date_counts.empty:
        print("âš ï¸  æ²¡æœ‰æ—¥æœŸæ•°æ®")
        return
    
    for date, count in date_counts.head(10).items():
        readable_date = format_date(date)
        print(f'  {readable_date}: {count:,} åªè‚¡ç¥¨')
    
    # æ‰¾å‡ºéœ€è¦è¡¥é½çš„è‚¡ç¥¨
    most_common_date = date_counts.index[0]
    most_common_count = date_counts.iloc[0]
    readable_most_common = format_date(most_common_date)
    
    print(f'\næœ€æ–°æ—¥æœŸ: {readable_most_common} ({most_common_count:,} åªè‚¡ç¥¨)')
    
    outdated_stocks = meta_df[meta_df['last_date'] != most_common_date]
    
    if not outdated_stocks.empty:
        print(f'\nâš ï¸  éœ€è¦è¡¥é½æ•°æ®çš„è‚¡ç¥¨æ•°é‡: {len(outdated_stocks):,}')
        
        print('\néœ€è¦è¡¥é½çš„è‚¡ç¥¨è¯¦æƒ…ï¼ˆå‰20ä¸ªï¼‰:')
        for _, row in outdated_stocks.head(20).iterrows():
            ts_code = row['ts_code']
            last_date = format_date(row['last_date'])
            
            stock_info = stock_basic[stock_basic['ts_code'] == ts_code]
            name = stock_info.iloc[0]['name'] if not stock_info.empty else 'æœªçŸ¥'
            
            print(f'  {ts_code} ({name}): æœ€æ–°æ•°æ®åˆ° {last_date}')
        
        if len(outdated_stocks) > 20:
            print(f'  ... è¿˜æœ‰ {len(outdated_stocks) - 20:,} åªè‚¡ç¥¨éœ€è¦è¡¥é½')
        
        # æŒ‰ç»“æŸæ—¥æœŸåˆ†ç»„ç»Ÿè®¡
        print('\næŒ‰ç»“æŸæ—¥æœŸåˆ†ç»„çš„éœ€è¡¥é½è‚¡ç¥¨:')
        outdated_date_counts = outdated_stocks['last_date'].value_counts()
        for date, count in outdated_date_counts.items():
            readable_date = format_date(date)
            print(f'  {readable_date}: {count:,} åªè‚¡ç¥¨')
        
        # åˆ†æéœ€è¦è¡¥é½çš„è‚¡ç¥¨ç‰¹å¾
        outdated_codes = outdated_stocks['ts_code'].tolist()
        outdated_stock_info = stock_basic[stock_basic['ts_code'].isin(outdated_codes)]
        
        if not outdated_stock_info.empty:
            print('\néœ€è¡¥é½è‚¡ç¥¨çš„åˆ†å¸ƒç‰¹å¾:')
            # æŒ‰äº¤æ˜“æ‰€åˆ†ç»„
            exchange_counts = outdated_stock_info['ts_code'].str[-2:].value_counts()
            print('  æŒ‰äº¤æ˜“æ‰€åˆ†å¸ƒ:')
            for exchange, count in exchange_counts.items():
                exchange_name = 'SH(ä¸Šäº¤æ‰€)' if exchange == 'SH' else 'SZ(æ·±äº¤æ‰€)'
                print(f'    {exchange_name}: {count:,} åª')
    else:
        print('\nâœ… æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ®éƒ½æ˜¯æœ€æ–°çš„ï¼')

def generate_recommendations(missing_codes, meta_df):
    """ç”Ÿæˆè¡¥é½å»ºè®®"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ æ•°æ®è¡¥é½å»ºè®®")
    print("=" * 60)
    
    recommendations = []
    
    if missing_codes and len(missing_codes) > 0:
        recommendations.append(f"å‘ç° {len(missing_codes):,} åªè‚¡ç¥¨æœªä¸‹è½½1åˆ†é’Ÿæ•°æ®")
        recommendations.append("å»ºè®®æ‰§è¡Œ: python main.py --fill-missing-minutes")
        recommendations.append("æˆ–ä½¿ç”¨äº¤äº’å¼èœå•: python start.pyï¼Œé€‰æ‹© [c] è¡¥é½åˆ†é’Ÿæ•°æ®")
    
    if meta_df is not None and 'last_date' in meta_df.columns:
        date_counts = meta_df['last_date'].value_counts()
        if not date_counts.empty:
            most_common_date = date_counts.index[0]
            outdated_stocks = meta_df[meta_df['last_date'] != most_common_date]
            if not outdated_stocks.empty:
                recommendations.append(f"å‘ç° {len(outdated_stocks):,} åªè‚¡ç¥¨æ•°æ®ä¸æ˜¯æœ€æ–°çš„")
                recommendations.append("å»ºè®®æ‰§è¡Œ: python start.py --incremental --6")
                recommendations.append("æˆ–ä½¿ç”¨äº¤äº’å¼èœå•: python start.pyï¼Œé€‰æ‹© [6] Aè‚¡1åˆ†é’Ÿæ•°æ®ä¸‹è½½ï¼ˆå¢é‡æ¨¡å¼ï¼‰")
    
    if not recommendations:
        print("âœ… æ•°æ®çŠ¶æ€è‰¯å¥½ï¼Œæ— éœ€è¡¥é½")
    else:
        print("å»ºè®®çš„è¡¥é½æ­¥éª¤:")
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec}")

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("ğŸ”¬ Aè‚¡1åˆ†é’Ÿæ•°æ®å¥åº·æ£€æŸ¥æŠ¥å‘Š")
    print("=" * 60)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # 1. åŸºç¡€çŠ¶æ€æ£€æŸ¥
    stock_basic, downloaded_files, missing_codes = check_basic_status()
    if stock_basic is None:
        sys.exit(1)
    
    # 2. æ—¶é—´èŒƒå›´åˆ†æ
    df_ranges = analyze_time_ranges(downloaded_files, stock_basic)
    
    # 3. å…ƒæ•°æ®æ£€æŸ¥
    meta_df = check_metadata()
    
    # 4. å®Œæ•´æ€§åˆ†æ
    analyze_completeness(stock_basic, meta_df)
    
    # 5. ç”Ÿæˆå»ºè®®
    generate_recommendations(missing_codes, meta_df)
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æ€»ç»“")
    print("=" * 60)
    
    if downloaded_files:
        print(f"âœ… å·²ä¸‹è½½è‚¡ç¥¨æ•°é‡: {len(downloaded_files):,}")
    if missing_codes:
        print(f"âš ï¸  æœªä¸‹è½½è‚¡ç¥¨æ•°é‡: {len(missing_codes):,}")
    if meta_df is not None:
        print(f"âœ… å…ƒæ•°æ®è®°å½•æ•°: {len(meta_df):,}")
    
    print("\næŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")

if __name__ == "__main__":
    main()

